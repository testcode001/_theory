数据源-->Surface-->SurfaceTexture-->GlSurfaceView(textureID)、TextureView
其中音视频解码-->展示又分为一下几种：
1.USB Device外设(MedicCodec硬解码)
2.camera sensor：系统camera类解码
3.本地文件、网络文件：(ijkPlayer.setDataSource()解码)
视频流：分辨率，帧率，比特率(CBR,VBR),通道数，位深
显示屏：宽高比
视频流通过纹理id(纹理类型为GLES11Ext.GL_TEXTURE_EXTERNAL_OES)和opengl关联
1.OpenGL 
2.EGL环境搭建(EGLDisplay.EGLConfig.EGLSurface.EGLContext) EGL版本
3.GLSL数据类型，修饰符，内置变量，内置函数texture2D().mix()
	顶点坐标，顶点变换矩阵(MVP模型.视图.投影矩阵坐标系变换)
	纹理坐标，纹理变换矩阵

shader脚本：
美颜：红润，磨皮，美白
美型：大眼，瘦脸，红腮，红唇
shader内置函数: mix texture2D
红润：本质就是改变色调。
磨皮：本质就是让像素点模糊，可以使用高斯模糊，但是可能导致边缘会不清晰，用双边滤波(Bilateral Filter) ，有针对性的模糊像素点，能保证边缘不被模糊。
美白：本质就是提高亮度。
图像画质相关的：亮度.色度.饱和度.对比度.暗角
3A+曝光铁三角：
【3A，Auto focus，Auto white balance，Auto flash】+【曝光铁三角，光圈、快门、iso，】：(曝光补偿？)
http://www.fsbus.com/danfanrumen/20594.html


OpenGL ES						
https://blog.csdn.net/junzia/article/category/6462864
https://blog.csdn.net/jxt1234and2010/article/details/53440644
glFramebufferTexture2D
https://www.jianshu.com/p/29a7dde7d21f
opengl EGL						
https://blog.csdn.net/ieearth/article/details/71180457						
https://blog.csdn.net/iEearth/article/details/78845105
opengl shader内置函数
https://blog.csdn.net/u010607947/article/details/76431474?utm_source=blogxgwz5	

opengl
https://learnopengl-cn.github.io/
https://juejin.im/post/5e4b4fe96fb9a07c9a1955a1
shader教程：顶点着色器和片段着色器是用叫GLSL的类C语言写成的，它包含一些针对向量和矩阵的操作。
https://learnopengl-cn.github.io/01%20Getting%20started/05%20Shaders/
纹理：(shader纹理变量或者纹理层级使用前要先启用或者激活)、纹理id、纹理类型及参数设置、渲染到纹理层级、shader纹理变量、
https://learnopengl-cn.github.io/01%20Getting%20started/06%20Textures/
https://juejin.im/post/5e4b4fe96fb9a07c9a1955a1

setEGLContextClientVersion(3); // Pick an OpenGL ES 2.0 context.
OpenGL ES 3.0中将2.0的attribute改成了in，顶点着色器的varying改成out，片段着色器的varying改成了in，也就是说顶点着色器的输出就是片段着色器的输入，另外uniform跟2.0用法一样
in或者out变量等不能在函数内（如main函数内）声明
OpenGL ES 2.0的gl_FragColor和gl_FragData在3.0中取消掉了，需要自己定义out变量作为片段着色器的输出颜色，如 out vec4 fragColor;。gl_Position还存在
OpenGL ES 3.0的shader中没有texture2D和texture3D等了，全部使用texture替换
-----------------------------------------------------------------------------------------------------
《Android 3D 游戏开发技术宝典 OpenGL ES 2.0》

shader：
attribute、gl_Position一定是顶点着色器，gl_FragColor、precision medium float一定是片段着色器。
顶点着色器shader：
顶点坐标和纹理坐标内存申请及赋值
纹理着色器shader：
普通绘制，图片sampler2D只需要纹理坐标，不需要纹理采样矩阵
视频OES需要纹理采样矩阵
vec4 nColor=texture2D(vTexture,aCoordinate);内置函数

顶点坐标.坐标系，顶点投影.视图.模型.矩阵
没有图片时(则不需要纹理坐标)，为使同一帧的不同顶点.不同像素有不同的颜色：须顶点坐标和颜色坐标都在顶点着色器中解析赋值，且一一对应。
纹理坐标.坐标系。
纹理id--(只有视频帧OES.yuv需要纹理采样矩阵，图片sampler2D.rgb不需要纹理采样矩阵)
opengles纹理操作:
1.激活纹理层级GL_TEXTURE0.即纹理容器
2.生成纹理ID.或生成帧缓冲ID.即显存地址
3.绑定纹理类型.或绑定帧缓冲类型(GLES30.GL_TEXTURE_2D、GLES11Ext.GL_TEXTURE_EXTERNAL_OES)：将纹理id和相应的纹理类型进行绑定
		GLES20.glBindTexture(GLES20.GL_TEXTURE_2D, textureId);
        GLES30.glBindFramebuffer(GLES30.GL_FRAMEBUFFER, mFrameBuffers[0]);
4.设置纹理类型参数：
纹理环绕方式：
可以使用glTexParameter()对单独的一个坐标轴设置（s轴、t轴、r轴）
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_MIRRORED_REPEAT);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_MIRRORED_REPEAT);
纹理过滤：
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);//放大(Magnify)过滤
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);//缩小(Minify)过滤
纹理过滤有很多个选项，最重要的两种即GL_NEAREST和GL_LINEAR。
GL_NEAREST（也叫邻近过滤，Nearest Neighbor Filtering）是OpenGL ES默认的纹理过滤方式。当设置为GL_NEAREST的时候，OpenGL ES会选择中心点最接近纹理坐标的那个像素。
GL_LINEAR（也叫线性过滤，(Bi)linear Filtering）它会基于纹理坐标附近的纹理像素，计算出一个插值，近似出这些纹理像素之间的颜色。
多级纹理
GLES20.glGenerateMipmap(GLES20.GL_TEXTURE_2D);
https://www.jianshu.com/p/609d6856b5cf
Android OpenGL绘制纹理图片：GLUtils.texImage2D(GLES20.GL_TEXTURE_2D, 0, bitmap, 0);
纹理坐标相当于：srcRect
顶点坐标相当于：dstRect
显示区域，绘制区域，纹理坐标区域
https://blog.csdn.net/yu540135101/article/details/100782542

onDrawFrame()方法中对shager中的变量进行赋值：启用顶点属性数组.设置顶点属性指针(即顶点坐标.纹理坐标)，设置glUniformMatrix4fv矩阵
6.显示纹理glDrawArrays(GL_TRIANGLE_STRIP, 0, 4);
        GLES20.glDrawElements(GLES20.GL_TRIANGLE_STRIP, m_drawOrder.length, GLES20.GL_UNSIGNED_SHORT, m_drawListBuffer);
eglSwapBuffers(display, winSurface); //窗口显示，交换双缓冲区

生成渲染缓冲id
绑定渲染缓冲id
设置渲染缓冲宽高
解绑渲染缓冲
glGenRenderbuffers(1, &depthStencil);
glBindRenderbuffer(GL_RENDERBUFFER, depthStencil);
glRenderbufferStorage(GL_RENDERBUFFER, GL_DEPTH24_STENCIL8, width, height);
glBindRenderbuffer(GL_RENDERBUFFER, 0);

生成帧缓冲id
绑定帧缓冲id
设置帧缓冲纹理类型
设置帧缓冲渲染buffer
glGenFramebuffers(1, &fbo);
glBindFramebuffer(GL_FRAMEBUFFER, fbo);
glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, color, 0);
glFramebufferRenderbuffer(GL_FRAMEBUFFER, GL_DEPTH_STENCIL_ATTACHMENT, GL_RENDERBUFFER, depthStencil);

VBO：
生成缓冲id
绑定缓冲id
绑定缓冲数据
glGenBuffers(...)
glBindBuffer(GLES20.GL_ARRAY_BUFFER, bufferId)
glBufferData(GLES20.GL_ARRAY_BUFFER, buffer.capacity() * elementSize, buffer, GLES20.GL_STATIC_DRAW)
指定了希望显卡如何管理给定的数据，它有三种形式：
① GL_STATIC_DRAW ：数据不会或几乎不会改变。
② GL_DYNAMIC_DRAW：数据会被改变很多。
③ GL_STREAM_DRAW：数据每次绘制时都会改变。
这边三角形的位置数据不会改变，每次渲染调用时都保持原样，所以它的使用类型最好是GL_STATIC_DRAW。
如果，一个缓冲中的数据将频繁被改变，那么使用的类型就是GL_DYNAMIC_DRAW或GL_STREAM_DRAW，这样就能确保显卡把数据放在能够高速写入的内存部分。

顶点坐标.纹理坐标内存空间申请并赋值
创建着色器，关联源码、编译，链接着色器程序
shader的属性location获取及赋值
生成纹理ID

顶点着色器、片段着色器   GLES20.glDrawArrays、GLES20.glDrawElements绘制，可根据顶点坐标数量，在onDrawFrame方法中调用多次***
https://blog.csdn.net/qq_35294564/article/details/86508493
顶点着色器决定坐标，片段着色器决定颜色，顶点着色器要把坐标传递给片段着色器
shader脚本中main函数外定义的变量(即uniform和attribute变量)，赋值数据是需要从外部程序传入的。

GLES20.glDelete...(...)释放GL资源

shader数据类型及修饰符：
矩阵加减乘除、向量加减乘除、矩阵与向量加减乘除
矩阵相乘即左行乘右列, 结果左列右行。矩阵与向量相乘，结果为向量。
矩阵乘法的本质是什么？
https://www.zhihu.com/question/21351965?sort=created
数据类型：
int
float
bool
mat4矩阵
vec4向量
sampler1D：1D纹理图片
sampler2D：2D纹理图片、samplerExternalOES视频帧纹理
sampler3D：3D纹理图片
sampleCube：立方贴图纹理
使用struct关键字声明类C的结构体
在 GLSL 中，可以声明任何类型的数组：vec3 position[20];
修饰符：
attribute数据类型只能用在vertexShader中，且只能用来修饰float标量、float向量以及矩阵变量，不能用来修饰其他类型的变量。用来定义如顶点位置、纹理坐标、法向量、颜色等等。
uniform用于定义全局变量，在一个像素绘制过程中是一个常量。用来定义如光源位置、统一变换矩阵、颜色等。
varying用于vertexShader向fragmentShader传递数据
const	用于声明常量
内置变量gl_Position和gl_FragColor都是vec4类型的向量，可通过 x.y.z.w和r.g.b.a来访问各个分量。
顶点着色器中的内建变量还有gl_PointSize 该值一般只有在采用了点绘制方式后才有意义。
片元着色器中的内建变量还有gl_FragCoord 和 gl_FrontFacing，这两个都是只读的，由渲染管线中片元着色器之前的阶段生成。
gl_FragCoord是一个vec4类型，其含有当前片元相对于窗口位置的坐标值 x、y、z 与 1/w 。其中 x 与 y 分别为片元相对于窗口的二维坐标，z 部分为该片元的深度值。
通过该内建变量可以实现与窗口位置相关的操作，例如，仅绘制窗口中指定区域内容等。
gl_FrontFacing 是一个布尔类型的内建变量，通过读取该内建变量的值可以判断正在处理的片元是否属于在光栅化阶段生成此片元的对应图元的正面。
如果属于正面，gl_FrontFacing的值为true，反之为false 。
search：GLSL内置函数及变量
https://www.jianshu.com/p/9f5b8ffe7771
all：在所有为真的时候，返回为真；
any：在任一变量为真的时候，返回为真；
dot：向量点乘
cross：向量的叉积
ceil(x)：向上取整 如：ceil(3.5) 值为4
floor(x)：向下取整 如：floor(3.5) 值为3
pow(x,y)：求x的y次方
exp(x)：自然指数e的x次方
exp2(x)：2的x次方
transpose：矩阵求转置矩阵
determinant：求行列式
inverse：矩阵求逆矩阵
distance：计算两点的距离
length：求解向量的长度
normalize：对一个向量进行标准化
clamp：将一个值截取到两个值之间
matrixCompMult：在两个矩阵之间执行一个逐分量的操作
outerProduct：提取两个向量的外积，这个函数的作用就是将一个n*1的向量与1*m的向量相乘，得到一个n*m的矩阵
一般默认都用弧度；
radians(degree) : 角度变弧度；
degrees(radian) : 弧度变角度；
sin(angle), cos(angle), tan(angle)
asin(x): arc sine, 返回弧度 [-PI/2, PI/2];
acos(x): arc cosine,返回弧度 [0, PI];
atan(y, x): arc tangent, 返回弧度 [-PI, PI];
atan(y/x): arc tangent, 返回弧度 [-PI/2, PI/2];
pow(x, y): x的y次方；
exp(x): 指数, log(x)：
exp2(x): 2的x次方， log2(x):
sqrt(x): x的根号； inversesqrt(x): x根号的倒数
abs(x): 绝对值
sign(x): 符号, 1, 0 或 -1
floor(x): 底部取整
ceil(x): 顶部取整
fract(x): 取小数部分
mod(x, y): 取模， x - y*floor(x/y)
min(x, y): 取最小值
max(x, y): 取最大值
clamp(x, min, max):  min(max(x, min), max);
step(edge, x): 如 x
smoothstep(edge0, edge1, x): threshod  smooth transition时使用。 edge0<=edge0时为0.0， x>=edge1时为1.
length(x): 向量长度
distance(p0, p1): 两点距离， length(p0-p1);
dot(x, y): 点积，各分量分别相乘 后 相加
cross(x, y): 差积，x[1]*y[2]-y[1]*x[2], x[2]*y[0] - y[2]*x[0], x[0]*y[1] - y[0]*x[1]
normalize(x): 归一化， length(x)=1;
faceforward(N, I, Nref): 如 dot(Nref, I)< 0则N, 否则 -N
reflect(I, N): I的反射方向， I -2*dot(N, I)*N, N必须先归一化
refract(I, N, eta): 折射，k=1.0-eta*eta*(1.0 - dot(N, I) * dot(N, I)); 如k<0.0 则0.0，否则 eta*I - (eta*dot(N, I)+sqrt(k))*N
matrixCompMult(matX, matY): 矩阵相乘, 每个分量 自行相乘， 即 r[i][j] = x[i][j]*y[i][j];   矩阵线性相乘，直接用 * 
lessThan(vecX, vecY): 向量 每个分量比较 x < y
lessThanEqual(vecX, vecY): 向量 每个分量比较 x<=y
greaterThan(vecX, vecY): 向量 每个分量比较 x>y
greaterThanEqual(vecX, vecY): 向量 每个分量比较 x>=y
equal(vecX, vecY): 向量 每个分量比较 x==y
notEqual(vecX, vexY): 向量 每个分量比较 x!=y
any(bvecX): 只要有一个分量是true， 则true
all(bvecX): 所有分量是true， 则true
not(bvecX): 所有分量取反
mix(x, y, a): x, y的线性混叠， x(1-a) + y*a;
texture2D(sampler2D, coord): texture lookup
texture2D(sampler2D, coord, bias): LOD bias, mip-mapped texture
texture2DProj(sampler2D, coord):
texture2DProj(sampler2D, coord, bias):
texture2DLod(sampler2D, coord, lod):
texture2DProjLod(sampler2D, coord, lod):
textureCube(samplerCube, coord):
textureCube(samplerCube, coord, bias):
textureCubeLod(samplerCube, coord, lod): 
https://blog.csdn.net/q1398284020/article/details/80181803
https://www.khronos.org/registry/OpenGL-Refpages/gl4/html/
http://docs.gl/sl4/exp2

shader属性赋值：
shader属性赋值时，只有attribute属性需要告诉opengl其解析结构及如何解析，其他类型属性直接赋值即可。因为attribute vec4传递可少于4个float的数组， 但必须告诉顶点属性指针如何解析。
顶点属性赋值时Stride步长参数: 要么为0，要么=vertexPerSizeCount*4Float
uniform修饰的和mat4类型的数据必须传递指定相等长度的数组



(不需要顶点着色器和片段着色器)，纹理id(视频OES.yuv、图片sampler2D.rgb)-->FrameBufferObject(FBO)帧缓冲容器实现离屏渲染-->glFlash()、glFinish()绘制更新 ？
Frame Buffer Object（FBO）即为帧缓冲对象，用于离屏渲染缓冲。相对于其它同类技术，如数据拷贝或交换缓冲区等，使用FBO技术会更高效并且更容易实现。而且FBO不受窗口大小限制。FBO可以包含许多颜色缓冲区，可以同时从一个片元着色器写入。
FBO是一个容器，自身不能用于渲染，需要与一些可渲染的缓冲区绑定在一起，像纹理或者渲染缓冲区。Render Buffer Object（RBO）即为渲染缓冲对象，分为color buffer(颜色)、depth buffer(深度)、stencil buffer(模板)。
在使用FBO做离屏渲染时，可以只绑定纹理，也可以只绑定Render Buffer，也可以都绑定或者绑定多个，视使用场景而定。
如只是对一个图像做变色处理等，只绑定纹理即可。如果需要往一个图像上增加3D的模型和贴纸，则一定还要绑定depth Render Buffer。
https://blog.csdn.net/junzia/article/details/53861519
https://blog.csdn.net/junzia/article/details/56008902
glBindFramebuffer(GL_DRAW_FRAMEBUFFER, 0);	//写缓冲
glBindFramebuffer(GL_READ_FRAMEBUFFER, mRenderSurfaces[0]->fboHandle);	//读缓冲
glBlitFramebuffer(mRenderSurfaces[0]->viewport.x,
                  mRenderSurfaces[0]->viewport.y,
                  mRenderSurfaces[0]->viewport.width,
                  mRenderSurfaces[0]->viewport.height,
                  0,
                  0,
                  mWindowWidth,
                  mWindowHeight,
                  GL_COLOR_BUFFER_BIT,
                  GL_LINEAR);
glBindFramebuffer(GL_READ_FRAMEBUFFER, 0);
glFinish();
绑定缓冲区对象表示选择未来的操作（对数据进行初始化或者使用缓冲区对象进行渲染）将影响哪个缓冲区对象。glBindBuffer (GLenum target, GLuint buffer)
FBO在创建后,使用前必须绑定它.glBindFramebuffer (GLenum target, GLuint framebuffer)
	
IntBuffer RGBABuffer = IntBuffer.allocate(width * height);
RGBABuffer.position(0);
GLES20.glReadPixels(0, 0, width, height,GLES20.GL_RGBA,GLES20.GL_UNSIGNED_BYTE,RGBABuffer); //复制显存图像数据到内存got RGB colors in framebuffer 
int[] pixls = RGBABuffer.array();
GL_TEXTURE_2D(RGB?)  GL_TEXTURE_EXTERNAL_OES(YUV?)

shareContext:
mEglContext=mEgl.eglCreateContext(mEglDisplay,mEglConfig,shareContext,contextAttr);

2d顶点坐标
3d顶点坐标

FBO帧缓冲对象容器.离屏渲染
在渲染时，先渲染到 FBO 上，在渲染到屏幕上。首先要切换到 FBO 进行渲染：GLES20.glBindFramebuffer(GLES20.GL_FRAMEBUFFER, fboId);
如果fboId参数为0，则代表切换到默认的屏幕上进行绘制。
RBO(Renderbuffer Object)渲染缓冲对象
https://mp.weixin.qq.com/s?__biz=MzA4MjU1MDk3Ng==&mid=2451526569&idx=1&sn=b3eb001db2308b469ada2ce2fae04f04&chksm=886ffa06bf187310cc2e00ed954e697dc32d8f347786c55ed3354c6ab38a544f1f194739860d&scene=21#wechat_redirect
VAO、VBO、
单个Surface渲染多个纹理，实现画中画
https://blog.csdn.net/yu540135101/article/details/102950038
https://blog.csdn.net/yu540135101/category_9364854.html
https://www.cnblogs.com/lookof/archive/2010/02/07/1665486.html
glCopyTexImage2D定义一个2D纹理图像或者立方体映射纹理图像，其像素来自于当前帧缓冲区（而非glTexImage2D那样来自于客户端内存）
//设置FBO分配内存大小，绑定纹理之后glBindTexture
GLES20.glTexImage2D(GLES20.GL_TEXTURE_2D, 0, GLES20.GL_RGBA, 1000, 500, 0, GLES20.GL_RGBA, GLES20.GL_UNSIGNED_BYTE, null);
//解析绑定图片
Bitmap bitmap = BitmapFactory.decodeResource(context.getResources(), bitmapRes);
GLUtils.texImage2D(GLES20.GL_TEXTURE_2D, 0, bitmap, 0);

       



https://blog.csdn.net/huutu/article/details/53364170
Opengl4.0中可以进行离屏渲染，即创造一个帧缓存对象（FBO），绑定一个帧缓存对象后，所有对Opengl的操作都会针对这个帧缓存对象执行。
GPU渲染完数据在显存，回传内存的唯一方式glReadPixels函数。glReadPixels可以“把已经绘制好的像素（它可能已经被保存到显卡的显存中）读取到内存”，即读取帧缓存中的数据并保存到内存中
或用glCopyTexImage2D利用帧缓存中的数据建立纹理。

glDrawArray(...)-->glFlush()或glFinish()-->eglSwapBuffers(m_EGLDisplay, m_EGLSurface);
每次在写完绘图代码需要让其完成效果时我们需要在代码后面添加glFlush()或gLFinish()函数：
（1）gLFlush()作用是将缓冲区中的指令(无论是否为满)立刻送给图形硬件执行，发送完立即返回；
（2）glFinish()作用也是将缓冲区中的指令(无论是否为满)立刻送给图形硬件执行，但是要等待图形硬件执行完这些指令才返回。
因此，在绘图命令比较冗长的情况下，可以分段调用glFlush以清空命令队列并让显卡开始先执行这些命令，最后调用glFinish来同步。
举个例子：我的渲染器一共有9种shader，渲染时从shader0一直渲染到shader8，以前是在所有shader渲染完成后才调用glFinish
（注意：这里如果把glFinish换成glFlush，那么调用wglSwapBuffer的时候在不同的平台上会产生不同的结果，具体结果我也不清楚，个人感觉好像没什么问题，但是游戏的时钟系统会被扰乱——最明显的就是帧速算错），那么CPU就要等GPU绘图，浪费了大把大把的时间；
现在改成每个shader完成后调用一次glFlush，强制GPU开始执行命令队列中的GL命令，最后调用glFinish等待GPU完成当前帧渲染，然后调用wglSwapBuffer调换前后缓存。

OpenGL 绘图的机制是: 先用 OpenGL 的绘图上下文 Rendering Context (简称为 RC )把图画好，再把所绘结果通过 SwapBuffer() 函数传给 Window 的 绘图上下文 Device Context (简记为 DC).
要注意的是，程序运行过程中，可以有多个 DC，但只能有一个 RC。因此当一个 DC 画完图后，要立即释放 RC，以便其它的 DC 也使用。
-----------------------------------------------------------------------------------------------------

在 OpenGL 坐标系统 文章中，根据点的坐标变换得出了如下的公式：
Vector{clip_gl_Position}=Matrix{projection投影矩阵} * Matrix{view/eye视图矩阵} * Matrix{model模型矩阵} * Vector{local_a_Position坐标向量}
这个公式每左乘一个矩阵，都代表了一种坐标系的变换。
投影矩阵决定视景体。视图矩阵的相机参数要在投影矩阵的near和far参数之间，否则绘制不出图像.即看不到图像。
模型矩阵可能包含了物体的平移(translation)、旋转(rotation)、缩放(scaling)这三种变换。
转化为着色器脚本语言如下：
attribute vec4 a_Position;
uniform mat4 u_ModelMatrix;
uniform mat4 u_ProjectionMatrix;
uniform mat4 u_ViewMatrix;
void main()
{
    gl_Position  = u_ProjectionMatrix * u_ViewMatrix * u_ModelMatrix * a_Position;//看起来三个变换的顺序跟我们期望的相反了，但这正是矩阵左乘造成的结果。
}
frustumM和perspectiveM都可以创建透视投影矩阵，只是创建参数不同，orthoM创建正交投影矩阵。正交投影会创建一个类似立方体的视景体。透视投影创建是一个锥形的视景体。
由投影矩阵创建的范围，是一个封闭的空间几何体，被称为视景体。
不管是正交投影还是透视投影，最终都是将视景体内的物体投影在近平面上，这也是 3D 坐标转换到 2D 坐标的关键一步。而近平面上的坐标接着也会转换成归一化设备坐标，再映射到屏幕视口上。

投影矩阵：投影矩阵决定视景体。只有绘制在近平面和远平面之间的内容，才能被用户看到？
Matrix.frustumM(mProjMatrix, 0, left, right, bottom, top, near, far)创建透视投影矩阵：
float left, //near面的left 
float right, //near面的right 
float bottom, //near面的bottom 
float top, //near面的top 
float near, //near面距离 
float far //far面距离 
投影矩阵的左、上、右、下距离都是相对于近平面中心的。近平面的坐标原点位于中心， X轴向右为正方向，Y轴向上为正方向，所以我们的 left、bottom 要为负数，而 right、top 要为正数。
近平面near参数和远平面far参数的距离都是指相对于视点的距离，所以 near、far 要为正数。
由于透视投影会产生近大远小的效果，当照相机位置不变，改变 near 的值时也会改变物体大小，near 越小，则离视点越近，相当于物体越远，那么显示的物体也就越小了。
当然也可以 near 和 far 的距离不动，改变摄像机的位置来改变观察到的物体大小。
设置这些参数能起到的作用：先是left，right和bottom,top，这4个参数会影响图像左右和上下缩放比，所以往往会设置的值分别-(float) width / height和(float) width / height，
top和bottom和top会影响上下缩放比，如果left和right已经设置好缩放，则bottom只需要设置为-1，top设置为1，这样就能保持图像不变形。
也可以将left，right 与bottom，top交换比例，即bottom和top设置为 -height/width 和 height/width, left和right设置为-1和1。 
near和far参数稍抽象一点，就是一个立方体的前面和后面，near和far需要结合拍摄相机即观察者眼睛的位置来设置，
例如setLookAtM中设置cx = 0, cy = 0, cz = 10，near设置的范围需要是小于10才可以看得到绘制的图像，如果大于10，图像就会处于了观察这眼睛的后面，这样绘制的图像就会消失在镜头前，
far参数影响的是立体图形的背面，far一定比near大，一般会设置得比较大，如果比较小，一旦3D图形尺寸很大，这时由于far太小，这个投影矩阵没法容纳图形全部的背面，这样3D图形的背面会有部分隐藏掉的。

视图矩阵：视图矩阵的相机参数要在投影矩阵的near和far参数之间，否则绘制不出图像.即看不到图像
要定义一个摄像机，或者说要定义一个摄像机视角为坐标原点的坐标系，需要：
1.摄像机在世界空间中的位置
2.摄像机观察的方向
3.指向摄像机右测的向量
4.指向摄像机上方的向量
Matrix.setLookAtM(mVMatrix, 0, cx, cy, cz, tx, ty, tz, upx, upy, upz)创建视图矩阵：
需要填充的参数 
float cx, //摄像机位置x 
float cy, //摄像机位置y 
float cz, //摄像机位置z 
float tx, //摄像机目标点x 
float ty, //摄像机目标点y 
float tz, //摄像机目标点z 
float upx, //摄像机UP向量X分量 
float upy, //摄像机UP向量Y分量 
float upz //摄像机UP向量Z分量 
这个方法看起来很抽象，设几组参数对比一下效果：
摄像机目标点，即绘制的3D图像，tx，ty, tz,为图像的中心位置设置到原点即 tx = 0,ty = 0, tz = 0; 
摄像机的位置，即观察者眼睛的位置 我们设置在目标点的正前方（位置z轴正方向），cx = 0, cy = 0, cz = 10; 
接着是摄像机顶部的方向了，如下图，很显然相机旋转，up的方向就会改变，这样就会会影响到绘制图像的角度。 
当用视图矩阵确定了照相机的位置时，要确保物体距离视点的位置在 near 和 far 的区间范围内，否则就会看不到物体。

模型矩阵：可能包含了缩放(scaling)、旋转(rotation)、平移(translation)这三种变换。
Matrix.setIdentityM(mTransMatrix, 0)		创建一个单位矩阵
Matrix.scaleM(mTransMatrix,0,2f,0.5f,1f)
Matrix.rotateM(mTransMatrix, 0, mAngle, 0f, 0f, 1.0f)
Matrix.translateM(mTransMatrix, 0, 0.5f, 0.5f, 0f)
--------------------------------------------------------------------------------

对视频中的某个内容进行替换，换成自己的图片，这个怎么用 OpenGL 去实现呢？
glEnable(GL_BLEND);//启用混合
glBlendFunc(GL_SRC_ALPHA, GL_ONE_MINUS_SRC_ALPHA)//颜色混合，设置混合源因子和目标因子所占比例
// todo绘制
glDisable(GL_BLEND)
混色的基本原理就是把要绘制的物体的颜色与屏幕上已经绘制好的颜色以一定比例来混合，最后的颜色看上去就像半透明一样。
在进行混合时，绘制的顺序十分重要。因为在绘制时，正要绘制上去的是源颜色，原来存在的是目标颜色，因此先绘制的物体就成为目标颜色，后来绘制的则成为源颜色。
绘制的顺序要考虑清楚，将目标颜色和设置的目标因子相对应，源颜色和设置的源因子相对应。
在进行三维混合时，不仅要考虑源因子和目标因子，还应该考虑深度缓冲区。必须先绘制所有不透明的物体，再绘制半透明的物体。
在绘制半透明物体时前，还需要将深度缓冲区设置为只读形式，否则可能出现画面错误

实现三维混合，总结起来，绘制顺序就是：首先绘制所有不透明的物体。如果两个物体都是不透明的，则谁先谁后 都没有关系。然后，将深度缓冲区设置为只读。
接下来，绘制所有半透明的物体。如果两个物体都是半透明的，则谁先谁后只需要根据自己的意愿（注意了，先绘制 的将成为“目标颜色”，后绘制的将成为“源颜色”，所以绘制的顺序将会对结果造成一些影响）。
最后，将深度缓冲区设置为可读可写形式。
glDepthMask(GL_FALSE);可将深度缓冲区设置为只读形式。
glDepthMask(GL_TRUE);可将深度缓冲区设置为可读可写形式。
glEnable(GL_DEPTH_TEST);可将深度缓冲区启用
glDisable(GL_DEPTH_TEST);可直接将深度缓冲区禁用
https://www.jianshu.com/p/b1544b0fc72c

在进行三维场景的混合时必须注意的，那就是深度缓冲。
深 度缓冲是这样一段数据，它记录了每一个像素距离观察者有多近。在启用深度缓冲测试的情况下，如果将要绘制的像素比原来的像素更近，则像素将被绘制。否则， 像素就会被忽略掉，不进行绘制。
这在绘制不透明的物体时非常有用——不管是先绘制近的物体再绘制远的物体，还是先绘制远的物体再绘制近的物体，或者干脆以 混乱的顺序进行绘制，最后的显示结果总是近的物体遮住远的物体。
--------------------------------------------------------------------------------------
opengl glsl编程类似于C语言编程，用形参指针作为返回值。形参容器，offset，length
opengl--EGL环境搭建
https://mp.weixin.qq.com/s?__biz=MzA4MjU1MDk3Ng==&mid=2451526566&idx=1&sn=44eae0fe0d0f758789fa29fc41109018&chksm=886ffa09bf18731f8e45f98de2bcc86c407b239499c2874a11f451dd8622f57f628588b9dd66&scene=178#rd
https://www.jianshu.com/p/9db986365cda
EGL 的使用要遵循一些固定的步骤，按照这些步骤去配置、创建、渲染、释放。
EGLDisplay.EGLConfig是对实际显示设备的抽象
EGLSurface是对用来存储图像的内存区域
EGLContext存储OpenGL ES绘图的一些状态信息
FrameBuffer的抽象，包括 Color Buffer，Depth Buffer，Stencil Buffer
在GLSurfaceView中可获取当前EGL环境的EGLDisplay、EGLSurface、EGLContext
mEGLContext = EGL14.eglGetCurrentContext();
mEGLSurface = EGL14.eglGetCurrentSurface();
mEGLDisplay = EGL14.eglGetCurrentDisplay();

【1】
创建与本地窗口系统的连接：调用 eglGetDisplay 方法得到 EGLDisplay。 mEGLDisplay = EGL14.eglGetDisplay(EGL14.EGL_DEFAULT_DISPLAY);
初始化 EGL 方法：调用 eglInitialize 方法初始化
// EGL 的主版本号
private int[] mMajorVersion = new int[1];
// EGL 的次版本号
private int[] mMinorVersion = new int[1];
boolean result = EGL14.eglInitialize(mEGLDisplay, mMajorVersion, 0, mMajorVersion, 0);

确定渲染表面的配置信息：调用 eglChooseConfig 方法得到 EGLConfig
 // 所有符合配置的 EGLConfig 个数
int[] numConfigs = new int[1];
// 所有符合配置的 EGLConfig
EGLConfig[] configs = new EGLConfig[1];
   //EglchooseConfig used this config设置画面的颜色、深度、模板位深
        int[] EGL_CONFIG ={
		EGL10.EGL_SURFACE_TYPE, EGL10.EGL_PBUFFER_BIT, 
		EGL10.EGL_RED_SIZE, 8,
		EGL10.EGL_GREEN_SIZE, 8,
		EGL10.EGL_BLUE_SIZE, 8,
		EGL10.EGL_ALPHA_SIZE, 8,
		EGL10.EGL_DEPTH_SIZE, 24, //请求深度缓冲区  
		EGL10.EGL_STENCIL_SIZE, 8,//请求模版缓冲区 
		EGL10.EGL_NONE //egl的所有属性config，最后要以 EGL14.EGL_NONE 结尾。
	 };
关于EGL10.EGL_SURFACE_TYPE, ：如果你要创建的是PbufferSurface后台显示，就需要EGL10.EGL_PBUFFER_BIT，如果要创建WindowSurface(前台显示)，需要EGL10.EGL_WINDOW_BIT类型
// configs 参数为 null,会在 numConfigs 中输出所有满足 EGL_CONFIG 条件的 config 个数
EGL14.eglChooseConfig(mEGLDisplay, EGL_CONFIG, 0, null, 0, 0, numConfigs, 0);
// 得到满足条件的个数
int num = numConfigs[0];
if (num != 0) {
    // 会获取所有满足 EGL_CONFIG 的 config
    EGL14.eglChooseConfig(mEGLDisplay, EGL_CONFIG, 0, configs, 0, configs.length, numConfigs, 0);
    // 去第一个
    mEGLConfig = configs[0];
}
【2.1】
创建渲染上下文：通过 EGLDisplay 和 EGLConfig ，调用 eglCreateContext 方法创建渲染上下文，得到 EGLContext
private static final int[] EGL_ATTRIBUTE = {
    EGL14.EGL_CONTEXT_CLIENT_VERSION, 2,
    EGL14.EGL_NONE,
};
private EGLContext mEGLContext = EGL14.EGL_NO_CONTEXT;
// 创建上下文
mEGLContext = EGL14.eglCreateContext(mEGLDisplay, mEGLConfig, EGL14.EGL_NO_CONTEXT, EGL_ATTRIBUTE, 0);
【2.2】
创建渲染表面：通过 EGLDisplay 和 EGLConfig ，调用 eglCreateWindowSurface 方法创建渲染表面，得到 EGLSurface
【2.2.a】对于渲染到屏幕上的创建，配置信息可以不添加什么，但还是要以 EGL14.EGL_NONE 结尾。
// 创建渲染表面的配置信息
private static final int[] EGL_SURFACE = {
        EGL14.EGL_NONE,
};
private EGLSurface mEGLSurface = EGL14.EGL_NO_SURFACE;
// surface 参数是有 SurfaceView.getHolder 传递过来的
mEGLSurface = EGL14.eglCreateWindowSurface(mEGLDisplay, mEGLConfig, surface, EGL_SURFACE, 0);
【2.2.b】
而对于离屏的渲染表面创建，就还需要提供宽、高等信息，但是却不需要提供 surface 的参数了。
// 使用 eglCreatePbufferSurface 就需要指定宽和高
int[] EGL_SURFACE = {
    EGL10.EGL_WIDTH, w,
    EGL10.EGL_HEIGHT, h,
    EGL10.EGL_NONE,
};
mEGLSurface = mEGL.eglCreatePbufferSurface(mEGLDisplay, mEGLConfig, EGL_SURFACE,0);
【3】
绑定上下文：通过 eglMakeCurrent 方法将 EGLSurface、EGLContext、EGLDisplay 三者绑定，接下来就可以使用 OpenGL 进行绘制了。
EGL14.eglMakeCurrent(mEGLDisplay, mEGLSurface, mEGLSurface, mEGLContext);
交换缓冲：当用 OpenGL 绘制结束后，使用 eglSwapBuffers 方法交换前后缓冲，将绘制内容显示到屏幕上
EGL14.eglSwapBuffers(mEGLDisplay, mEGLSurface);
【4】
释放 EGL 环境：绘制结束，不再需要使用 EGL 时，取消 eglMakeCurrent 的绑定，销毁  EGLDisplay、EGLSurface、EGLContext。
EGL14.eglMakeCurrent(mEGLDisplay, EGL14.EGL_NO_SURFACE, EGL14.EGL_NO_SURFACE, EGL14.EGL_NO_CONTEXT);
EGL14.eglDestroyContext(mEGLDisplay, mEGLContext);
EGL14.eglDestroySurface(mEGLDisplay, mEGLSurface);
EGL14.eglReleaseThread();
EGL14.eglTerminate(mEGLDisplay);
mEGLContext = EGL14.EGL_NO_CONTEXT;
mEGLDisplay = EGL14.EGL_NO_DISPLAY;
mEGLConfig = null;
GLES20.glDelete...()


对于SwapBuffers，SwapBuffer命令只是把前台和后台的缓冲区指针交换一下而已也就是把前台的内容变成后台缓冲的内容，把后台的缓冲内容换到了前台。
这个函数它本身并不对换过来的成为了后台的buffer做清理工作，所以每帧都glClear一次，然后再绘制，而后再SwapBuffers。
GLES20.glClear(GLES20.GL_COLOR_BUFFER_BIT | GLES20.GL_DEPTH_BUFFER_BIT | GLES20.GL_STENCIL_BUFFER_BIT); //清除颜色、深度、模板缓存
GLES20.glClearColor(0f,0f,0f, 1f);//设置背景色

EGL14.eglCreatePbufferSurface(EGLDisplay dpy, EGLConfig config, int[] attrib_list, int offset)
EGL14.eglCreateWindowSurface (EGLDisplay dpy, EGLConfig config, Object win, int[] attrib_list, int offset)
EGL14.eglMakeCurrent(EGLDisplay dpy, EGLSurface draw, EGLSurface read, EGLContext ctx)
EGL14.eglSwapBuffers(EGLDisplay dpy, EGLSurface surface)
https://blog.csdn.net/helldevil/article/details/7513946



